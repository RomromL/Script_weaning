{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]\n",
      "NumPy version: 1.23.5\n",
      "pandas version: 1.5.3\n",
      "matplotlib: 3.7.1\n",
      "TSfresh: 0.20.0\n",
      "Sklearn version: 1.1.3\n",
      "Xgboost version: 1.5.0\n",
      "Lightgbm version: 2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\miniconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "%run library_TS.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE TIMESERIES AND GROUP THEN IN A DICTIONNARY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to make feature extraction is to load the TS files (containing in different folder and subfolder), and group them by variable type (RR, cardiac rate...) and by index (in the name of the files). To do that we make a dictionnary, including in the key the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "DataFrame 0001 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0003 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0005 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0006 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0008 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0009 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0011 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0013 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0014 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0015 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0016 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0017 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0018 : 548 lignes, 13 colonnes\n",
      "DataFrame 0019 : 1388 lignes, 15 colonnes\n",
      "DataFrame 0020 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0021 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0022 : 1440 lignes, 13 colonnes\n",
      "DataFrame 0023 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0025 : 286 lignes, 15 colonnes\n",
      "DataFrame 0026 : 1440 lignes, 12 colonnes\n",
      "DataFrame 0027 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0028 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0029 : 1440 lignes, 14 colonnes\n",
      "DataFrame 0030 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0031 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0032 : 1125 lignes, 16 colonnes\n",
      "DataFrame 0033 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0035 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0036 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0037 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0038 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0039 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0040 : 1246 lignes, 16 colonnes\n",
      "DataFrame 0041 : 351 lignes, 16 colonnes\n",
      "DataFrame 0042 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0043 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0044 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0045 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0046 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0047 : 703 lignes, 13 colonnes\n",
      "DataFrame 0048 : 498 lignes, 13 colonnes\n",
      "DataFrame 0049 : 1432 lignes, 16 colonnes\n",
      "DataFrame 0050 : 1379 lignes, 16 colonnes\n",
      "DataFrame 0051 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0052 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0053 : 1439 lignes, 16 colonnes\n",
      "DataFrame 0054 : 1409 lignes, 16 colonnes\n",
      "DataFrame 0055 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0056 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0057 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0058 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0059 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0060 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0061 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0062 : 1400 lignes, 15 colonnes\n",
      "DataFrame 0063 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0064 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0065 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0066 : 1439 lignes, 15 colonnes\n",
      "DataFrame 0067 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0068 : 1374 lignes, 15 colonnes\n",
      "DataFrame 0069 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0070 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0071 : 1439 lignes, 16 colonnes\n",
      "DataFrame 0072 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0073 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0074 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0075 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0076 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0077 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0078 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0079 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0080 : 1106 lignes, 16 colonnes\n",
      "DataFrame 0081 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0082 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0083 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0084 : 888 lignes, 16 colonnes\n",
      "DataFrame 0085 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0086 : 1321 lignes, 15 colonnes\n",
      "DataFrame 0087 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0088 : 1393 lignes, 15 colonnes\n",
      "DataFrame 0089 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0090 : 1270 lignes, 16 colonnes\n",
      "DataFrame 0091 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0092 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0093 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0094 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0095 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0096 : 1130 lignes, 16 colonnes\n",
      "DataFrame 0097 : 1410 lignes, 16 colonnes\n",
      "DataFrame 0098 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0099 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0100 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0101 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0102 : 1415 lignes, 16 colonnes\n",
      "DataFrame 0103 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0104 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0105 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0106 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0107 : 1435 lignes, 16 colonnes\n",
      "DataFrame 0108 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0109 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0110 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0111 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0112 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0113 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0114 : 1440 lignes, 13 colonnes\n",
      "DataFrame 0115 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0116 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0117 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0118 : 1380 lignes, 16 colonnes\n",
      "DataFrame 0119 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0120 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0121 : 1440 lignes, 12 colonnes\n",
      "DataFrame 0122 : 1440 lignes, 14 colonnes\n",
      "DataFrame 0123 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0124 : 1440 lignes, 14 colonnes\n",
      "DataFrame 0125 : 1414 lignes, 16 colonnes\n",
      "DataFrame 0126 : 855 lignes, 16 colonnes\n",
      "DataFrame 0127 : 1440 lignes, 12 colonnes\n",
      "DataFrame 0128 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0129 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0130 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0131 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0132 : 1439 lignes, 16 colonnes\n",
      "DataFrame 0133 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0134 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0135 : 1144 lignes, 16 colonnes\n",
      "DataFrame 0136 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0137 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0138 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0139 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0140 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0141 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0142 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0143 : 908 lignes, 16 colonnes\n",
      "DataFrame 0144 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0145 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0146 : 1395 lignes, 15 colonnes\n",
      "DataFrame 0147 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0148 : 1363 lignes, 16 colonnes\n",
      "DataFrame 0149 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0150 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0151 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0152 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0153 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0154 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0155 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0156 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0157 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0158 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0159 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0160 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0161 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0162 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0163 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0164 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0165 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0166 : 1270 lignes, 16 colonnes\n",
      "DataFrame 0167 : 728 lignes, 16 colonnes\n",
      "DataFrame 0168 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0169 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0170 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0171 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0172 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0173 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0174 : 1256 lignes, 16 colonnes\n",
      "DataFrame 0175 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0176 : 1440 lignes, 13 colonnes\n",
      "DataFrame 0177 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0178 : 1440 lignes, 13 colonnes\n",
      "DataFrame 0179 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0180 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0181 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0182 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0183 : 1229 lignes, 16 colonnes\n",
      "DataFrame 0184 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0185 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0186 : 1401 lignes, 16 colonnes\n",
      "DataFrame 0187 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0188 : 1440 lignes, 11 colonnes\n",
      "DataFrame 0189 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0190 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0191 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0192 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0193 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0194 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0195 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0196 : 996 lignes, 15 colonnes\n",
      "DataFrame 0197 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0198 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0199 : 1437 lignes, 16 colonnes\n",
      "DataFrame 0200 : 1173 lignes, 16 colonnes\n",
      "DataFrame 0201 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0202 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0203 : 1393 lignes, 16 colonnes\n",
      "DataFrame 0204 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0205 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0206 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0207 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0208 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0209 : 1406 lignes, 16 colonnes\n",
      "DataFrame 0210 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0211 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0212 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0213 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0214 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0215 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0216 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0217 : 1440 lignes, 16 colonnes\n",
      "DataFrame 0218 : 1401 lignes, 15 colonnes\n",
      "DataFrame 0219 : 1440 lignes, 15 colonnes\n",
      "DataFrame 0220 : 1440 lignes, 15 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Defintion of the master folder path containing all the TS files\n",
    "parent_folder = \"C:/Users/Windows/Documents/Essai/TS_truncate_24H\"\n",
    "\n",
    "# All patients list\n",
    "folder_path = \"C:/Users/Windows/Documents/Essai/TS_truncate_24H/Hemodynamique/Hourly_Diuresis/\"\n",
    "\n",
    "lst_pat = [os.path.splitext(filename)[0] for filename in os.listdir(folder_path)]\n",
    "lst_pat.sort()\n",
    "txt_files = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(parent_folder):\n",
    "    # Filtering the txt files and add their name in a list\n",
    "    txt_files += [os.path.join(root, file) for file in files if file.endswith('.txt')]\n",
    "# Dictionnary initialisation for containing all the df for every patient\n",
    "dico_df  = {}\n",
    "\n",
    "# For every txt find :\n",
    "for pat in lst_pat:\n",
    "   df_temp = pd.DataFrame()\n",
    "   for file in [i for i in txt_files if pat in i]:\n",
    "        # Rename\n",
    "        variable = file[file.rfind(\"\\\\\", 0, file.rfind(\"\\\\\") - 1) + 1:file.rfind(\"\\\\\")]\n",
    "        try :\n",
    "            temp = pd.read_csv(file, delimiter='\\t', header=None, index_col=0).iloc[:,0:1].rename(columns = {1: variable})\n",
    "            temp.index = pd.to_datetime(temp.index)\n",
    "            if temp[temp.columns[0]].dtypes == 'object': # Transformation of the object variable (with numb >999) in float\n",
    "                temp.iloc[:, 0] = temp.iloc[:, 0].apply(lambda x: re.sub(r'\\s+', '', x))\n",
    "            temp[temp.columns[0]] = temp[temp.columns[0]].astype('float')\n",
    "            #temp.iloc[:, 0] = temp.iloc[:, 0].astype('float')\n",
    "            #temp = temp.astype({\"\": int, \"Proverty_rate\": float, \"Median_Age\": int }) 0].str.replace(' ', '')\n",
    "        except EmptyDataError:\n",
    "            temp = pd.DataFrame()\n",
    "            #temp = pd.DataFrame({variable: [0]})\n",
    "        #lst_df = lst_df.append(temp)\n",
    "        df_temp = pd.concat([df_temp,temp], ignore_index=False, axis=1)\n",
    "   if not df_temp.empty:\n",
    "       df_temp = df_temp.groupby(df_temp.index.floor('H'), group_keys=False).apply(lambda s: s.ffill().bfill())\n",
    "       df_temp.fillna(method='ffill', inplace=True)\n",
    "       df_temp.fillna(df_temp.median(), inplace=True)\n",
    "   dico_df[pat] = df_temp\n",
    "\n",
    "print(len(dico_df))\n",
    "for key, df in dico_df.items():\n",
    "    print(f\"DataFrame {key} : {df.shape[0]} lignes, {df.shape[1]} colonnes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE THE DICTIONNARY TO FEATURE EXTRACTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the library need to import the label csv, and to convert the dictionnary into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of X dataset is 295772\n",
      "The length of target is 213\n"
     ]
    }
   ],
   "source": [
    "# Importation of the target csv \n",
    "target_df = pd.read_excel(\"//wsl.localhost/Ubuntu/home/romain/GITHUB/Extub-IA/BDD/Target.xls\", dtype=str, index_col=None, usecols=[\"ID\", \"Weaning_success\"])\n",
    "\n",
    "# Definition of the ID\n",
    "sequence_ids = target_df['ID']\n",
    "# Definition of the label\n",
    "labels = target_df['Weaning_success']\n",
    "\n",
    "X = pd.DataFrame()\n",
    "y = labels\n",
    "\n",
    "# Fill the X dataset with the dictionnary created previously\n",
    "for i, sequence in enumerate(sequence_ids):\n",
    "    df = dico_df[sequence].copy()\n",
    "    df.insert(0, 'sequence', i)\n",
    "    df['step'] = np.arange(df.shape[0]) # creates a range of integers starting from 0 to the number of the measurements.\n",
    "    X = pd.concat([X, df])\n",
    "print(f\"The length of X dataset is {len(X)}\")\n",
    "print(f\"The length of target is {len(y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value before imputation:\n",
      "sequence                   0\n",
      "CR                      1440\n",
      "Cumulative_Diuresis     2880\n",
      "DBP                    11829\n",
      "Hourly_Diuresis            0\n",
      "MAP                    11829\n",
      "SBP                    13269\n",
      "Glycemia                 286\n",
      "CPIS                    2880\n",
      "Temperature             2880\n",
      "RASS                   65474\n",
      "FiO2                       0\n",
      "Minute_Volume              0\n",
      "PEEP                       0\n",
      "RR                      7113\n",
      "SpO2                       0\n",
      "Tidal_Volume            5760\n",
      "step                       0\n",
      "dtype: int64\n",
      "-----------------------------------\n",
      "Missing value after imputation::\n",
      "sequence               0\n",
      "CR                     0\n",
      "Cumulative_Diuresis    0\n",
      "DBP                    0\n",
      "Hourly_Diuresis        0\n",
      "MAP                    0\n",
      "SBP                    0\n",
      "Glycemia               0\n",
      "CPIS                   0\n",
      "Temperature            0\n",
      "RASS                   0\n",
      "FiO2                   0\n",
      "Minute_Volume          0\n",
      "PEEP                   0\n",
      "RR                     0\n",
      "SpO2                   0\n",
      "Tidal_Volume           0\n",
      "step                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the missing value\n",
    "print(f'Missing value before imputation:\\n{X.isna().sum()}')\n",
    "print(f'-----------------------------------')\n",
    "\n",
    "# Replace the missing value by the mean\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Display the missing value\n",
    "print(f'Missing value after imputation::\\n{X.isna().sum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTION FEATURE "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the data are prepared, we can extract the feature. For this we used TSFresh. Many calculations are made and take time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 50/50 [3:26:33<00:00, 247.87s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction done in 12395.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# Extraction all the features for X dataset\n",
    "# The parameters default_fc_parameters=xxx permit to select the feature we want\n",
    "# https://stackoverflow.com/questions/50426458/retrieve-specific-features-by-using-tsfresh-in-python\n",
    "\n",
    "time_start = time.perf_counter()\n",
    "extracted_features = extract_features(X, column_id='sequence', column_sort='step', n_jobs= 10)\n",
    "#n_jobs definites the parallelisation\n",
    "\n",
    "time_elapsed = (time.perf_counter()-time_start)\n",
    "print(\"extraction done in %.2f seconds\" %(time_elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 50/50 [00:09<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction done in 10.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# We can also define the feature we want, like mean, max and min, variance : \n",
    "fc_parameters = {\n",
    "    \"mean\": None,\n",
    "    \"maximum\":None, \n",
    "    \"minimum\":None, \n",
    "    \"variance\":None\n",
    "}\n",
    "\n",
    "time_start = time.perf_counter()\n",
    "\n",
    "extracted_features2 = extract_features(X, column_id='sequence', column_sort='step', n_jobs= 10, default_fc_parameters =fc_parameters)\n",
    "\n",
    "time_elapsed = (time.perf_counter()-time_start)\n",
    "print(\"extraction done in %.2f seconds\" %(time_elapsed))\n",
    "\n",
    "extracted_features2.to_csv('Minimal Feature extraction.csv', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the full extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features.to_csv('All features extracted.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extraction we can made another imputation, with the function impute() of TSfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\miniconda3\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:198: RuntimeWarning: The columns ['RR__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'RR__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'RR__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'RR__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'RR__max_langevin_fixed_point__m_3__r_30'\n",
      " 'RR__query_similarity_count__query_None__threshold_0.0'\n",
      " 'SpO2__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'SpO2__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'SpO2__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'SpO2__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'SpO2__max_langevin_fixed_point__m_3__r_30'\n",
      " 'SpO2__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Tidal_Volume__query_similarity_count__query_None__threshold_0.0'\n",
      " 'CR__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Cumulative_Diuresis__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'Cumulative_Diuresis__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'Cumulative_Diuresis__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'Cumulative_Diuresis__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'Cumulative_Diuresis__max_langevin_fixed_point__m_3__r_30'\n",
      " 'Cumulative_Diuresis__query_similarity_count__query_None__threshold_0.0'\n",
      " 'DBP__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Hourly_Diuresis__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'Hourly_Diuresis__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'Hourly_Diuresis__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'Hourly_Diuresis__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'Hourly_Diuresis__max_langevin_fixed_point__m_3__r_30'\n",
      " 'Hourly_Diuresis__query_similarity_count__query_None__threshold_0.0'\n",
      " 'MAP__query_similarity_count__query_None__threshold_0.0'\n",
      " 'SBP__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Glycemia__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'Glycemia__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'Glycemia__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'Glycemia__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'Glycemia__max_langevin_fixed_point__m_3__r_30'\n",
      " 'Glycemia__query_similarity_count__query_None__threshold_0.0'\n",
      " 'CPIS__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'CPIS__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'CPIS__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'CPIS__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'CPIS__max_langevin_fixed_point__m_3__r_30'\n",
      " 'CPIS__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Temperature__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'Temperature__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'Temperature__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'Temperature__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'Temperature__max_langevin_fixed_point__m_3__r_30'\n",
      " 'Temperature__query_similarity_count__query_None__threshold_0.0'\n",
      " 'RASS__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'RASS__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'RASS__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'RASS__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'RASS__max_langevin_fixed_point__m_3__r_30'\n",
      " 'RASS__query_similarity_count__query_None__threshold_0.0'\n",
      " 'FiO2__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'FiO2__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'FiO2__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'FiO2__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'FiO2__max_langevin_fixed_point__m_3__r_30'\n",
      " 'FiO2__query_similarity_count__query_None__threshold_0.0'\n",
      " 'Minute_Volume__query_similarity_count__query_None__threshold_0.0'\n",
      " 'PEEP__friedrich_coefficients__coeff_0__m_3__r_30'\n",
      " 'PEEP__friedrich_coefficients__coeff_1__m_3__r_30'\n",
      " 'PEEP__friedrich_coefficients__coeff_2__m_3__r_30'\n",
      " 'PEEP__friedrich_coefficients__coeff_3__m_3__r_30'\n",
      " 'PEEP__max_langevin_fixed_point__m_3__r_30'\n",
      " 'PEEP__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imputation with TSFresh\n",
    "impute(extracted_features)\n",
    "\n",
    "# Reset the index\n",
    "y = y.reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIMENSION REDUCTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have XX new column extract. It's too big to make good prediction and classification. So we made dimension reduction, by the FRESH method. Consisting in take only the relevant features determined with a univariate statistic test. After this calculation, all the p-value are corrected with the Benjamini-Hochberg method and we take only the XX first one, or the p-value <0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features extracted : 12608\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features extracted :\",len(extracted_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraction done in 10.16 seconds\n",
      "nombre de colonne du df filtré: 150\n"
     ]
    }
   ],
   "source": [
    "y_label = y['Weaning_success'].squeeze()\n",
    "\n",
    "# Calculate the relevance table https://tsfresh.readthedocs.io/en/latest/text/feature_filtering.html\n",
    "time_start = time.perf_counter()\n",
    "relevance_table = calculate_relevance_table(extracted_features, y_label, ml_task='classification')\n",
    "#relevance_table = relevance_table[relevance_table.relevant] only if we have enought data\n",
    "relevance_table.sort_values(\"p_value\", inplace=True) # Sort by ascending P-value\n",
    "\n",
    "#list_feature = relevance_table[\"feature\"][relevance_table.p_value<0.05] # Take only the feature with p-value<0.05\n",
    "list_feature = relevance_table[\"feature\"][:150] # or take the 150th first columns\n",
    "\n",
    "filter_features = extracted_features.loc[:,list_feature]\n",
    "\n",
    "time_elapsed = (time.perf_counter()-time_start)\n",
    "print(\"extraction done in %.2f seconds\" %(time_elapsed))\n",
    "\n",
    "print(f'nombre de colonne du df filtré:', len(filter_features.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filter features extracted in csv\n",
    "filter_features.to_csv('Filtered features extracted (150 features).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
